{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67df8ca0-b43b-43d3-9a7d-b2af3feb5be6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'set_random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[0;32m      8\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1234\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m tf\u001b[38;5;241m.\u001b[39mset_random_seed(\u001b[38;5;241m1234\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m     12\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'set_random_seed'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "PATH = './'\n",
    "V = 1.0 \n",
    "T = 1 \n",
    "\n",
    "Net_layer = [2] + [5] * 3 + [1] \n",
    "test_Number = ''\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--adam', default=100000, type=int)\n",
    "parser.add_argument('--lbfgs', default=50000, type=int)\n",
    "parser.add_argument('--case', \n",
    "                    default='ADE_1bp_balanced', type=str, \n",
    "                    choices=(\"ADE_1bp_balanced\", \"ADE_1bp_imbalanced\", \"ADE_2bp_balanced\"))\n",
    "\n",
    "parser.add_argument('--lr', default=0.001, type=int)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "class CP_PINN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, XT_u_train, u_train, layers, lb, ub, l_t, l_x):\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.l_t = l_t\n",
    "        self.l_x = l_x\n",
    "        self.x   = XT_u_train[:,0:1]\n",
    "        self.t   = XT_u_train[:,1:2]\n",
    "        self.u   = u_train\n",
    "\n",
    "        self.diff_epsilon = tf.Variable(tf.truncated_normal([self.l_t, 1], dtype=tf.float64), dtype=tf.float64)\n",
    "        self.epsilon = tf.cumsum(self.diff_epsilon[::-1])[::-1]      \n",
    "       \n",
    "        self.x_tf   = tf.placeholder(tf.float64, shape=[None, self.x.shape[1]])\n",
    "        self.t_tf   = tf.placeholder(tf.float64, shape=[None, self.t.shape[1]])\n",
    "        self.u_tf   = tf.placeholder(tf.float64, shape=[None, self.u.shape[1]]) \n",
    "\n",
    "        self.weights, self.biases, self.a = self.initialize_NN(layers)\n",
    "\n",
    "      \n",
    "        self.u_NN_pred = self.net_u(self.x_tf, self.t_tf)\n",
    "        self.f_pred = self.net_f(self.x_tf, self.t_tf)\n",
    "   \n",
    "        self.loss_f = tf.reduce_sum(tf.square(self.u_tf - self.u_NN_pred))\n",
    "        self.loss_s = tf.reduce_sum(tf.square(self.f_pred))\n",
    "        ##### U-shape curve penalty\n",
    "        t = np.arange(1, l_t)\n",
    "        u = tf.constant(((self.l_t/(t*(self.l_t - t)))**.5 * 40 + 50), shape=[self.l_t - 1, 1], dtype = tf.float64)\n",
    "        self.loss_l1 = tf.reduce_sum(tf.multiply(u, tf.nn.relu(self.diff_epsilon[:-1]))) + tf.reduce_sum(tf.multiply(u, tf.nn.relu(-self.diff_epsilon[:-1])))\n",
    "        self.loss  = self.loss_f +self.loss_s + self.loss_l1\n",
    "\n",
    "                   \n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, method = 'L-BFGS-B', options = {'maxiter': args.lbfgs,\n",
    "                                                                                                      'maxfun': 50000,\n",
    "                                                                                                      'maxcor': 50,\n",
    "                                                                                                      'maxls': 50,\n",
    "                                                                                                      'ftol': 1.0 * np.finfo(float).eps})\n",
    "\n",
    "\n",
    "        self.LR = args.lr\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer(self.LR)\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.sess.run(self.init)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float64), dtype=tf.float64)\n",
    "            a = tf.Variable(0.01, dtype=tf.float64)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases, a\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim), dtype=np.float64)\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev,dtype=tf.float64), dtype=tf.float64)\n",
    " \n",
    "    \n",
    "    def neural_net(self, X, weights, biases, a):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = X \n",
    "        # H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "\n",
    "    def net_u(self, x, t):  \n",
    "        u = self.neural_net(tf.concat([x,t],1), self.weights, self.biases,  self.a)\n",
    "        return u\n",
    "\n",
    "    def net_dxu(self, x, t):\n",
    "        u   = self.net_u(x, t)\n",
    "        d1xu = tf.gradients(u, x)[0]\n",
    "        d2xu = tf.gradients(d1xu, x)[0]\n",
    "        return d1xu, d2xu\n",
    "    \n",
    "    def net_dtu(self, x, t):\n",
    "        u   = self.net_u(x, t)\n",
    "        d1tu = tf.gradients(u, t)[0]\n",
    "        return d1tu\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x,t)\n",
    "        d1tu = tf.gradients(u, t)[0]\n",
    "        d1xu = tf.gradients(u, x)[0]\n",
    "        d2xu = tf.gradients(d1xu, x)[0]\n",
    "        f = d1tu + V*d1xu - tf.reshape(self.diff_epsilon*tf.reshape(d2xu, [self.l_t, self.l_x]), [self.l_t*self.l_x, 1])\n",
    "        return f\n",
    "    \n",
    "    def lbfgs_callback(self, loss_value_s, loss_value_f, loss_valuel1, diff_epsilon):\n",
    "        str_print = ''.join(['Loss_s: %.3e, Loss_f: %.3e, LossL1: %.3e, Position: %d'])\n",
    "        print(str_print % (loss_value_s, loss_value_f, loss_valuel1, np.argmax(np.abs(diff_epsilon.flatten()[:-1]))))\n",
    "        \n",
    "###############################################################################\n",
    "    def train(self, nIter):\n",
    "        \n",
    "        \n",
    "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t, self.u_tf: self.u}\n",
    "        \n",
    "        total_time_train = 0\n",
    "        start_time       = time.time()\n",
    "        total_records    = []\n",
    "        error_records    = []\n",
    "\n",
    "        for it in range(nIter):\n",
    "            \n",
    "            start_time_train = time.time()\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            elapsed_time_train = time.time() - start_time_train\n",
    "            total_time_train = total_time_train + elapsed_time_train            \n",
    " \n",
    "            if it % 100 == 0:\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                loss_value_f= self.sess.run(self.loss_f, tf_dict)\n",
    "                loss_value_s= self.sess.run(self.loss_s, tf_dict)\n",
    "                loss_valuel1 = self.sess.run(self.loss_l1, tf_dict)\n",
    "                epsilon_value = self.sess.run(self.epsilon, tf_dict)\n",
    "                diff_epsilon = self.sess.run(self.diff_epsilon, tf_dict)\n",
    "                total_records.append(np.array([it, loss_value, np.mean(epsilon_value)]))\n",
    "                \n",
    "               \n",
    "            if it % 1000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                str_print = ''.join(['It: %d, Loss_s: %.3e, Loss_f: %.3e, LossL1: %.3e, Time: %.2f, TrTime: %.4f, Position: %d'])\n",
    "                print(str_print % (it, loss_value_s, loss_value_f, loss_valuel1, elapsed, elapsed_time_train, np.argmax(np.abs(diff_epsilon[:-1]))))\n",
    "                start_time = time.time()\n",
    "                \n",
    "        error_u = 1\n",
    "        error_records = [loss_value, error_u]\n",
    "\n",
    "        self.optimizer.minimize(self.sess, feed_dict = tf_dict, fetches = [self.loss_s, self.loss_f, self.loss_l1, self.diff_epsilon], \n",
    "                                loss_callback = self.lbfgs_callback)\n",
    "\n",
    "        loss_value = self.sess.run(self.loss, tf_dict)\n",
    "        loss_value_f= self.sess.run(self.loss_f, tf_dict)\n",
    "        loss_value_s= self.sess.run(self.loss_s, tf_dict)\n",
    "        loss_valuel1 = self.sess.run(self.loss_l1, tf_dict)\n",
    "        epsilon_value = self.sess.run(self.epsilon)\n",
    "        total_records.append(np.array([it + args.lbfgs, loss_value, np.mean(epsilon_value)]))\n",
    "\n",
    "\n",
    "        return epsilon_value, error_records, total_records, total_time_train\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "############## For breakpoint problems, we can generate two parts of data and concatenate them #######################\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    \n",
    "    \n",
    "    ###########################################################################    \n",
    "\n",
    "    def u_initial(x, t):\n",
    "        utemp = - np.sin(np.pi*x)\n",
    "        return utemp\n",
    "  \n",
    "    ###########################################################################\n",
    "    def u_ext(x, t, epsilon, trunc = 800):\n",
    "        \"\"\"\n",
    "        Function to compute the analytical solution as a Fourier series expansion.\n",
    "        Inputs:\n",
    "            x: column vector of locations\n",
    "            t: column vector of times\n",
    "            trunc: truncation number of Fourier bases\n",
    "        \"\"\"\n",
    "\n",
    "        # Series index:\n",
    "        p = np.arange(0, trunc+1.0)\n",
    "        p = np.reshape(p, [1, trunc+1])\n",
    "        \n",
    "        D = epsilon\n",
    "        c0 = 16*np.pi**2*D**3*V*np.exp(V/D/2*(x-V*t/2))                           # constant\n",
    "        \n",
    "        c1_n = (-1)**p*2*p*np.sin(p*np.pi*x)*np.exp(-D*p**2*np.pi**2*t)           # numerator of first component\n",
    "        c1_d = V**4 + 8*(V*np.pi*D)**2*(p**2+1) + 16*(np.pi*D)**4*(p**2-1)**2     # denominator of first component\n",
    "        c1 = np.sinh(V/D/2)*np.sum(c1_n/c1_d, axis=-1, keepdims=True)             # first component of the solution\n",
    "        \n",
    "        c2_n = (-1)**p*(2*p+1)*np.cos((p+0.5)*np.pi*x)*np.exp(-D*(2*p+1)**2*np.pi**2*t/4)\n",
    "        c2_d = V**4 + (V*np.pi*D)**2*(8*p**2+8*p+10) + (np.pi*D)**4*(4*p**2+4*p-3)**2\n",
    "        c2 = np.cosh(V/D/2)*np.sum(c2_n/c2_d, axis=-1, keepdims=True)       # second component of the solution\n",
    "        \n",
    "        c = c0*(c1+c2)\n",
    "\n",
    "        \n",
    "        \n",
    "        if t==0:\n",
    "            c = u_initial(x, t)\n",
    "        \n",
    "        return c\n",
    "\n",
    "\n",
    "    delta_test = 0.01 # time step\n",
    "    xtest = np.linspace(-1,1,500) \n",
    "    ttest = np.arange(0, T+delta_test, delta_test)\n",
    "\n",
    "    l_t = len(ttest)\n",
    "    l_x = len(xtest)\n",
    "\n",
    "    #data_temp = np.asarray([[ [xtest[i],ttest[j],u_ext(xtest[i],ttest[j], 1.5)] for i in range(len(xtest))] for j in range(len(ttest))])\n",
    "    ###############One change point#####################\n",
    "    data_temp = []\n",
    "\n",
    "\n",
    "    for j in range(len(ttest)):\n",
    "        if args.case == 'ADE_1bp_balanced':\n",
    "            if j < len(ttest) // 2: e = 1\n",
    "            else: e = 0.05\n",
    "        elif args.case == 'ADE_2bp_balanced':\n",
    "            if j < len(ttest) // 3: e = 1\n",
    "            elif j >= len(ttest) // 3  and j < 2*len(ttest) // 3: e = 0.05\n",
    "            else: e = 1\n",
    "        else:\n",
    "            if j < len(ttest) // 5: e = 1\n",
    "            else: e = 0.05\n",
    "        data_temp.append([[xtest[i],ttest[j],u_ext(xtest[i],ttest[j], e)] for i in range(len(xtest))])\n",
    "    data_temp = np.asarray(data_temp)\n",
    "\n",
    "    ttest=ttest[:,None]\n",
    "    xtest=xtest[:,None]\n",
    "    Xtest = data_temp.flatten()[0::3]\n",
    "    Ytest = data_temp.flatten()[1::3]\n",
    "    Exact = data_temp.flatten()[2::3]\n",
    "    XT_test = np.hstack((Xtest[:,None],Ytest[:,None])) # dim: TN x 2\n",
    "    u_test = Exact[:,None] # dim: TN x 1\n",
    "\n",
    "    lb = XT_test.min(0)\n",
    "    ub = XT_test.max(0)\n",
    "\n",
    "    model = CP_PINN(XT_test, u_test, Net_layer, lb, ub, l_t, l_x)\n",
    "    \n",
    "    total_record_total=[]\n",
    "#%%\n",
    "    epsilon_value, error_record, total_record, total_time_train\\\n",
    "    = model.train(args.adam)\n",
    "    total_record_total.append([total_record])\n",
    "#%%\n",
    "\n",
    "    np.savetxt('epsilon_value_' + args.case, epsilon_value.flatten(), delimiter=',')\n",
    "    \n",
    "    with open(''.join([PATH,str(args.case), str(test_Number),'_record.mat']), 'wb') as f:\n",
    "        scipy.io.savemat(f, {'x_test'      : XT_test})\n",
    "        scipy.io.savemat(f, {'u_test'      : u_test})\n",
    "        scipy.io.savemat(f, {'total'       : total_record})\n",
    "        scipy.io.savemat(f, {'total_time_train'   : total_time_train}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8950e3-81bb-4056-b5f9-376e18f07734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
